# AnÃ¡lise Preditiva de Diabetes â€” Pima Indians Dataset

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
![Status](https://img.shields.io/badge/Status-ConcluÃ­do-success.svg)

---

## ğŸ“˜ VisÃ£o Geral

Este projeto desenvolve modelos de **Machine Learning** para **detecÃ§Ã£o de diabetes**, utilizando o [Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database).

O foco estÃ¡ em **minimizar falsos negativos**, priorizando **sensibilidade (recall)** e mÃ©tricas balanceadas â€” fundamentais em diagnÃ³sticos mÃ©dicos.

---

## ğŸ”¬ Metodologia

### ğŸ§¹ PrÃ©-processamento
- IdentificaÃ§Ã£o e tratamento de **valores invÃ¡lidos (zeros mascarados)**.  
- ImputaÃ§Ã£o estatÃ­stica com base no comportamento das variÃ¡veis.  
- Tratamento diferenciado da variÃ¡vel **`Insulin`** por grupo de desfecho.  
- Escalonamento das variÃ¡veis com **StandardScaler**.  
- DivisÃ£o dos dados em **conjuntos de treino e teste estratificados**.

### ğŸ“Š AnÃ¡lise ExploratÃ³ria
- VisualizaÃ§Ã£o de distribuiÃ§Ãµes e assimetria das variÃ¡veis.  
- AnÃ¡lise de correlaÃ§Ãµes entre fatores clÃ­nicos e o desfecho (diabetes).  
- Uso de **boxplots** e **violinplots** para avaliar o impacto de variÃ¡veis no *outcome*.  

> Exemplo de visualizaÃ§Ãµes:
>
> ![DistribuiÃ§Ã£o da glicose](./images/glucose_distribution.png)  
*DistribuiÃ§Ã£o da glicose por classe de diabetes.*
> ![Matriz de correlaÃ§Ã£o](./images/correlation_matrix.png)  
*CorrelaÃ§Ã£o entre variÃ¡veis clÃ­nicas.*
> ![Violinplot - BMI vs Outcome](./images/violinplot_insulin_outcome.png)
*DistribuiÃ§Ã£o da insulina conforme o outcome.*  

### ğŸ¤– Modelagem
Foram testados trÃªs algoritmos de classificaÃ§Ã£o supervisionada:
- **RegressÃ£o LogÃ­stica**  
- **Decision Tree**  
- **Random Forest**

Os modelos foram avaliados pelas seguintes mÃ©tricas:  
**AcurÃ¡cia Balanceada**, **Recall**, **F1-score**, **AUC-ROC** e **Log-loss**.

---

## ğŸ§¾ Resultados

| Modelo | AcurÃ¡cia Balanceada | Recall | F1-score | AUC-ROC | Log-loss |
|--------|----------|--------|----------|----------|-----------|
| Logistic Regression | 0.74 | 0.56 | 0.66 | 0.88 | 0.41 |
| Decision Tree | 0.89 | 0.85 | 0.87 | 0.96 | 0.55 |
| **Random Forest**  | **0.92** | **0.88** | **0.90** | **0.97** | **0.23** |

> **Random Forest** apresentou o melhor desempenho geral, com Ã³timo equilÃ­brio entre sensibilidade e precisÃ£o, alÃ©m de menor log-loss â€” indicando previsÃµes mais confiÃ¡veis.

> ![Curva ROC - Random Forest](./images/roc_curve_rf.png)  
*curva ROC do Random Forest.*
> ![Matriz de confusÃ£o - Random Forest](./images/confusion_matrix_rf.png)
*Matriz de ConfusÃ£o do Random Forest.*

---

## ğŸ’¡ Principais Insights

- **Glucose** e **BMI** sÃ£o os preditores mais relevantes para o diagnÃ³stico.  
- A variÃ¡vel **Insulin** mostra padrÃµes distintos entre classes, justificando tratamento separado.  
- O **dataset Ã© desbalanceado**, o que reforÃ§a a importÃ¢ncia de mÃ©tricas sensÃ­veis Ã  classe minoritÃ¡ria.  
- A **idade** nÃ£o Ã© um fator isolado, mas potencializa risco quando combinada com outras variÃ¡veis.  
---

## ğŸ“ˆ PrÃ³ximos Passos

- Testar outros algoritmos de classificaÃ§Ã£o, como **K-Nearest Neighbors (KNN)** e **Gradient Boosting**.  
- Aplicar **validaÃ§Ã£o cruzada (k-fold)** para maior robustez dos resultados.  

---

## ğŸ› ï¸ Tecnologias

- **Linguagem:** Python 3.10+
- **AnÃ¡lise:** Pandas
- **VisualizaÃ§Ã£o:** Matplotlib, Seaborn
- **Machine Learning:** Scikit-learn
- **Ambiente:** Google Colab / Jupyter Notebook 

---

## ğŸ‘¤ Autor

**Vitor Santos**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/vitor-e-s-santos/) Â· âœ‰ï¸ vitore.santos@hotmail.com  

